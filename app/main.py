# =========================
# Path setup (MUST be first)
# =========================
import sys
import os

ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)

from services.user_insights import get_user_or_case_insights

# =========================
# Imports
# =========================
import streamlit as st
import pickle
import faiss

from sentence_transformers import SentenceTransformer
from services.retriever import find_similar_cases

# =========================
# Streamlit UI Config
# =========================
st.set_page_config(
    page_title="Auto MPR Recommendation",
    layout="wide"
)

st.title("🛠️ Auto MPR Response Recommendation Dashboard")

st.caption(
    "Recommendations are generated by semantically matching new MPR issues "
    "with historical cases using NLP-based similarity search."
)

# =========================
# 🔧 Control Panel
# =========================
st.subheader("🔧 Control Panel")

with st.container():
    col1, col2 = st.columns(2)

    with col1:
        scale = st.selectbox(
            "Data scale",
            options=["2k", "25k"],
            index=1
        )

    with col2:
        query_mode = st.radio(
            "Query type",
            options=[
                "General MPR Issue",
                "User-Specific View"
            ],
            horizontal=True
        )

# =========================
# Load heavy resources (scale-aware)
# =========================
@st.cache_resource
def load_resources(scale):
    model = SentenceTransformer("all-MiniLM-L6-v2")
    index = faiss.read_index(f"data/case_index_{scale}.faiss")
    with open(f"data/case_meta_{scale}.pkl", "rb") as f:
        metadata = pickle.load(f)
    return model, index, metadata


model, index, metadata = load_resources(scale)

# =========================
# User Input Section
# =========================
st.write(
    "Enter a new MPR issue and get similar past cases with suggested resolutions."
)

if query_mode == "General MPR Issue":
    query = st.text_area(
        "Enter MPR Issue",
        height=100,
        placeholder="Describe the issue..."
    )
else:
    user_id = st.text_input(
        "Enter User ID or User Name",
        placeholder="e.g. john.doe"
    )

# =========================
# Run Button
# =========================
run_clicked = st.button("Run")

# =========================
# General MPR Query Logic
# =========================
if run_clicked and query_mode == "General MPR Issue":
    if not query.strip():
        st.warning("Please enter an MPR issue.")
    else:
        with st.spinner("Searching similar past MPRs..."):
            results = find_similar_cases(
                query=query,
                model=model,
                index=index,
                metadata=metadata
            )

            results = sorted(
                results,
                key=lambda x: x.get("confidence", 0),
                reverse=True
            )

        st.subheader("🔍 Similar Historical Cases")

        IMPORTANT_FIELDS = [
            "caseid",
            "category",
            "reportedon",
            "subject",
            "details",
            "Resolution"
        ]

        for i, r in enumerate(results, 1):
            confidence = round(r.get("confidence", 0), 2)
            label = "🟢 Best Match" if i == 1 else ""

            with st.expander(
                f"Case {i} {label} — Match Confidence: {confidence}%"
            ):
                for field in IMPORTANT_FIELDS:
                    if field in r and r[field]:
                        st.write(f"**{field}**: {r[field]}")

        if results:
            best_case = results[0]
            st.subheader("✅ Recommended Resolution")
            st.success(
                "Based on the most similar historical MPR case:\n\n"
                + best_case.get(
                    "Resolution",
                    "Refer to the top similar case above."
                )
            )

# =========================
# User-Specific Placeholder
# =========================

# =========================
# User / Case Insights
# =========================
if run_clicked and query_mode == "User-Specific View":
    if not user_id.strip():
        st.warning("Please enter a caseID or full name.")
    else:
        insights = get_user_or_case_insights(user_id)

        if insights["data"] is None:
            st.error("No data found for the given input.")
        else:
            # -------------------------
            # Case-level view
            # -------------------------
            if insights["type"] == "case":
                case = insights["data"]

                st.subheader(f"📄 Case Details — {case['caseid']}")

                st.write(f"**Owner:** {case['currentowner']}")
                st.write(f"**Category:** {case['category']}")
                st.write(f"**Status:** {case['statuscode']}")
                st.write(f"**Aging (days):** {case['aging']}")
                st.write(f"**Reported On:** {case['reportedon']}")
                st.write(f"**Closed Date:** {case['closedate']}")

                st.markdown("**Subject**")
                st.write(case["subject"])

                st.markdown("**Details**")
                st.write(case["details"])

            # -------------------------
            # User-level summary view
            # -------------------------
            else:
                summary = insights["data"]

                st.subheader(f"👤 User Summary — {summary['owner']}")

                col1, col2, col3, col4 = st.columns(4)

                col1.metric("Total Cases", summary["total_cases"])
                col2.metric("Pending", summary["pending_cases"])
                col3.metric("Overdue (>7d)", summary["overdue_cases"])
                col4.metric("Critical (>21d)", summary["critical_cases"])

                st.markdown("### Status Breakdown")
                st.json(summary["status_breakdown"])

