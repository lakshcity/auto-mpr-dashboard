import pandas as pd
from pathlib import Path
import os
import pickle

# =========================
# Path setup - Points to project root
# =========================
BASE_DIR = Path(__file__).resolve().parent.parent # Moves up from services/ to root

# Priority paths for the metadata generated by your indexer
META_PATHS = [
    BASE_DIR / "data" / "case_meta_master.pkl",
]

# =========================
# Hardcoded Owner Mapping
# =========================
OWNER_MAP = {
    "aditya singh": 781, "akarsh bhatt": 6039, "amit anand": 827,
    "anubhav gupta": 4310, "deepali kumari": 5249, "dheeraj": 4776,
    "himanshu padaliya": 4019, "laksh gupta": 6035, "lisha gupta": 5443,
    "niharika verma": 4185, "sagar verma": 4777, "testinguserkam@6": 5437,
    "veeresh kumar verma": 5926, "vikas ojha": 3898, "vishal kumar": 5736,
    "vivek kumar": 3701, "yajurva tiwari": 3520
}

TERMINAL_STATUSES = ["Resolved", "Closed", "Invalid"]

# =========================
# Helpers
# =========================
def _to_float(val):
    try:
        if isinstance(val, str):
            clean_val = val.lower().replace("d", "").strip()
            return float(clean_val)
        return float(val)
    except Exception:
        return 0.0

def _raw_age_to_days(raw_val):
    x = _to_float(raw_val)
    if x <= 0:
        return 0.0
    if x > 1000:
        return x / 1440.0
    return x

def is_case_id(value: str) -> bool:
    return str(value).isdigit()





def _load_from_meta_pkl(p: Path) -> pd.DataFrame:
    with open(p, "rb") as f:
        records = pickle.load(f)
    df = pd.DataFrame(records)
    return df

def load_cases_df():
    """Only look for the file generated by indexer.py"""
    for p in META_PATHS:
        if p.exists():
            with open(p, "rb") as f:
                records = pickle.load(f)
            df = pd.DataFrame(records)
            return _normalize_df(df)
    
    # Precise error message to help you debug if the file moves
    raise FileNotFoundError(f"Indexer output not found. Checked: {META_PATHS[0]}")

def _normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.fillna("")

    # Map columns based on your logs: ['ownername', 'MPR_Subject', 'Statuscode']
    # We check for multiple variations to be safe
    if "currentowner" not in df.columns:
        df["currentowner"] = df["ownername"] if "ownername" in df.columns else ""

    if "mpr_subject" not in df.columns:
        if "MPR_Subject" in df.columns:
            df["mpr_subject"] = df["MPR_Subject"]
        elif "subject" in df.columns:
            df["mpr_subject"] = df["subject"]

    if "statuscode" not in df.columns:
        if "Statuscode" in df.columns:
            df["statuscode"] = df["Statuscode"]
        else:
            df["statuscode"] = "Pending"

    # Dates
    df["reportedon"] = pd.to_datetime(df["reportedon"], errors="coerce")
    df["closeddate"] = pd.to_datetime(df["closeddate"], errors="coerce")

    # Aging Calculation
    today = pd.Timestamp.now()
    def calc_aging_days(row):
        start = row["reportedon"]
        if pd.isnull(start): 
            return 0.0
        # If closed, age = Closed - Reported. If open, age = Today - Reported.
        end = row["closeddate"] if pd.notnull(row["closeddate"]) else today
        return max((end - start).total_seconds() / 86400.0, 0.0)

    df["aging_num"] = df.apply(calc_aging_days, axis=1)
    return df

# =========================
# Filtering helpers
# =========================
def _get_user_cases_by_owner(owner_name: str, df: pd.DataFrame):
    owner_key = owner_name.strip().lower()
    owner_id = OWNER_MAP.get(owner_key)

    if owner_id and "currentownerid" in df.columns:
        return df[df["currentownerid"] == owner_id]

    return df[
        df["currentowner"]
        .astype(str)
        .str.lower()
        .str.strip()
        .eq(owner_key)
    ]

def _get_user_cases(owner_name: str):
    df = load_cases_df()
    return _get_user_cases_by_owner(owner_name, df).copy()

def _get_active_user_cases(owner_name: str):
    user_df = _get_user_cases(owner_name)
    if user_df.empty:
        return pd.DataFrame()
    mask = ~user_df["statuscode"].astype(str).str.strip().isin(TERMINAL_STATUSES)
    return user_df[mask].copy()

# =========================
# Main Insight Function
# =========================
def get_user_or_case_insights(query_val: str):
    df = load_cases_df()
    query_val = str(query_val).strip()

    if is_case_id(query_val):
        case_match = df[df["caseid"].astype(str) == query_val]
        if not case_match.empty:
            return {"type": "case", "data": case_match.iloc[0].to_dict()}

    user_match = _get_user_cases(query_val)
    if user_match.empty:
        mask = df["currentowner"].astype(str).str.lower().str.contains(query_val.lower())
        user_match = df[mask].copy()

    if not user_match.empty:
        active_cases_df = _get_active_user_cases(user_match.iloc[0]["currentowner"])

        total = len(user_match)
        pending_count = len(active_cases_df[active_cases_df["aging_num"] <= 7])
        overdue = len(active_cases_df[(active_cases_df["aging_num"] > 7) & (active_cases_df["aging_num"] <= 21)])
        critical = len(active_cases_df[active_cases_df["aging_num"] > 21])

        status_counts = user_match["statuscode"].value_counts().to_dict()
        primary_owner = user_match.iloc[0]["currentowner"]

        summary = {
            "owner": primary_owner,
            "total_cases": total,
            "pending_cases": pending_count,
            "overdue_cases": overdue,
            "critical_cases": critical,
            "status_breakdown": status_counts
        }
        return {"type": "user", "data": summary}

    return {"type": "none", "data": None}

# =========================
# List Getter Functions
# =========================
def get_pending_cases(owner_name: str, top_n: int = 5):
    active_df = _get_active_user_cases(owner_name)
    if active_df.empty:
        return []
    fresh_df = active_df[active_df["aging_num"] <= 7].sort_values(by="aging_num", ascending=False)
    return fresh_df.head(top_n).to_dict(orient="records")

def get_overdue_cases(owner_name: str, top_n: int = 3):
    active_df = _get_active_user_cases(owner_name)
    if active_df.empty:
        return []
    overdue_df = active_df[(active_df["aging_num"] > 7) & (active_df["aging_num"] <= 21)].sort_values(by="aging_num", ascending=False)
    return overdue_df.head(top_n).to_dict(orient="records")

def get_critical_cases(owner_name: str, top_n: int = 3):
    active_df = _get_active_user_cases(owner_name)
    if active_df.empty:
        return []
    critical_df = active_df[active_df["aging_num"] > 21].sort_values(by="aging_num", ascending=False)
    return critical_df.head(top_n).to_dict(orient="records")

def get_recent_cases(owner, days=5):
    df = load_cases_df()
    user_df = _get_user_cases_by_owner(owner, df).copy()
    cutoff = pd.Timestamp.today() - pd.Timedelta(days=days)
    recent_df = user_df[user_df["reportedon"] >= cutoff]
    return recent_df.to_dict("records")

def get_latest_resolved_cases(owner_name: str, top_n: int = 3):
    df = load_cases_df()
    user_df = _get_user_cases_by_owner(owner_name, df).copy()

    resolved_df = user_df[
        (user_df["statuscode"].astype(str).str.strip() == "Resolved") |
        (user_df["closeddate"].notna())
    ].copy()

    resolved_df = resolved_df[resolved_df["closeddate"].notna()].copy()
    if resolved_df.empty:
        return []

    resolved_df = resolved_df.sort_values(by="closeddate", ascending=False)

    resolved_df["resolution_days"] = (
        (resolved_df["closeddate"] - resolved_df["reportedon"]).dt.total_seconds() / 86400.0
    ).fillna(0)

    for col in ["configurationeffort", "testingeffort", "totaleffort"]:
        if col in resolved_df.columns:
            resolved_df[col] = pd.to_numeric(resolved_df[col], errors="coerce").fillna(0)
        else:
            resolved_df[col] = 0

    return resolved_df.head(top_n).to_dict(orient="records")