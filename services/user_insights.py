import pandas as pd
from pathlib import Path
import os
import numpy as np
from datetime import datetime, timedelta
import pickle

# =========================
# Path setup - Points to project root
# =========================
BASE_DIR = Path(__file__).resolve().parent.parent  # Moves up from services/ to root
DATA_DIR = BASE_DIR / "data"

# Priority paths for the metadata generated by your indexer
META_PATHS = [
    DATA_DIR / "case_meta_master.pkl",
]

# =========================
# Hardcoded Owner Mapping
# =========================
OWNER_MAP = {
    "aditya singh": 781, "akarsh bhatt": 6039, "amit anand": 827,
    "anubhav gupta": 4310, "deepali kumari": 5249, "dheeraj": 4776,
    "himanshu padaliya": 4019, "laksh gupta": 6035, "lisha gupta": 5443,
    "niharika verma": 4185, "sagar verma": 4777, "testinguserkam@6": 5437,
    "veeresh kumar verma": 5926, "vikas ojha": 3898, "vishal kumar": 5736,
    "vivek kumar": 3701, "yajurva tiwari": 3520
}
TERMINAL_STATUSES = ["Resolved", "Closed", "Invalid"]

# =========================
# Helpers
# =========================
def _to_float(val):
    try:
        if isinstance(val, str):
            clean_val = val.lower().replace("d", "").strip()
            return float(clean_val)
        return float(val)
    except Exception:
        return 0.0

def _raw_age_to_days(raw_val):
    x = _to_float(raw_val)
    if x <= 0:
        return 0.0
    if x > 1000:
        return x / 1440.0
    return x

def is_case_id(value: str) -> bool:
    return str(value).isdigit()

def _load_from_meta_pkl(p: Path) -> pd.DataFrame:
    with open(p, "rb") as f:
        records = pickle.load(f)
    df = pd.DataFrame(records)
    return df

def business_days_between(start, end):
    if pd.isna(start) or pd.isna(end):
        return None
    return np.busday_count(start.date(), end.date())

def load_cases_df():
    """Only look for the file generated by indexer.py"""
    for p in META_PATHS:
        if p.exists():
            with open(p, "rb") as f:
                records = pickle.load(f)
            df = pd.DataFrame(records)
            return _normalize_df(df)
    # Precise error message to help you debug if the file moves
    raise FileNotFoundError(f"Indexer output not found. Checked: {META_PATHS[0]}")

def _normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.fillna("")
    # Map columns based on your logs: ['ownername', 'MPR_Subject', 'Statuscode']
    # We check for multiple variations to be safe
    if "currentowner" not in df.columns:
        df["currentowner"] = df["ownername"] if "ownername" in df.columns else ""
    if "mpr_subject" not in df.columns:
        if "MPR_Subject" in df.columns:
            df["mpr_subject"] = df["MPR_Subject"]
        elif "subject" in df.columns:
            df["mpr_subject"] = df["subject"]
    if "statuscode" not in df.columns:
        if "Statuscode" in df.columns:
            df["statuscode"] = df["Statuscode"]
        else:
            df["statuscode"] = "Pending"

    # Dates
    df["reportedon"] = pd.to_datetime(df["reportedon"], errors="coerce")
    df["closeddate"] = pd.to_datetime(df["closeddate"], errors="coerce")

    # Aging Calculation (calendar-days; KEEP for backward compatibility)
    today = pd.Timestamp.now()
    def calc_aging_days(row):
        start = row["reportedon"]
        if pd.isnull(start):
            return 0.0
        # If closed, age = Closed - Reported. If open, age = Today - Reported.
        end = row["closeddate"] if pd.notnull(row["closeddate"]) else today
        return max((end - start).total_seconds() / 86400.0, 0.0)

    df["aging_num"] = df.apply(calc_aging_days, axis=1)
    return df

# =========================
# Filtering helpers
# =========================
def _get_user_cases_by_owner(owner_name: str, df: pd.DataFrame):
    owner_key = owner_name.strip().lower()
    owner_id = OWNER_MAP.get(owner_key)
    if owner_id and "currentownerid" in df.columns:
        return df[df["currentownerid"] == owner_id]
    return df[
        df["currentowner"]
        .astype(str)
        .str.lower()
        .str.strip()
        .eq(owner_key)
    ]

def _get_user_cases(owner_name: str):
    df = load_cases_df()
    return _get_user_cases_by_owner(owner_name, df).copy()

def _get_active_user_cases(owner_name: str):
    user_df = _get_user_cases(owner_name)
    if user_df.empty:
        return pd.DataFrame()
    mask = ~user_df["statuscode"].astype(str).str.strip().isin(TERMINAL_STATUSES)
    return user_df[mask].copy()

# =========================
# Main Insight Function
# =========================
def get_user_or_case_insights(query_val: str):
    df = load_cases_df()
    query_val = str(query_val).strip()

    if is_case_id(query_val):
        case_match = df[df["caseid"].astype(str) == query_val]
        if not case_match.empty:
            return {"type": "case", "data": case_match.iloc[0].to_dict()}

    user_match = _get_user_cases(query_val)
    if user_match.empty:
        mask = df["currentowner"].astype(str).str.lower().str.contains(query_val.lower())
        user_match = df[mask].copy()

    if not user_match.empty:
        active_cases_df = _get_active_user_cases(user_match.iloc[0]["currentowner"])
        total = len(user_match)
        pending_count = len(active_cases_df[active_cases_df["aging_num"] <= 7])
        overdue = len(active_cases_df[(active_cases_df["aging_num"] > 7) & (active_cases_df["aging_num"] <= 21)])
        critical = len(active_cases_df[active_cases_df["aging_num"] > 21])
        status_counts = user_match["statuscode"].value_counts().to_dict()
        primary_owner = user_match.iloc[0]["currentowner"]
        summary = {
            "owner": primary_owner,
            "total_cases": total,
            "pending_cases": pending_count,
            "overdue_cases": overdue,
            "critical_cases": critical,
            "status_breakdown": status_counts
        }
        return {"type": "user", "data": summary}

    return {"type": "none", "data": None}

# =========================
# List Getter Functions (calendar-day versions - KEEP)
# =========================
def get_pending_cases(owner_name: str, top_n: int = 5):
    active_df = _get_active_user_cases(owner_name)
    if active_df.empty:
        return []
    fresh_df = active_df[active_df["aging_num"] <= 7].sort_values(by="aging_num", ascending=False)
    return fresh_df.head(top_n).to_dict(orient="records")

def get_overdue_cases(owner_name: str, top_n: int = 3):
    active_df = _get_active_user_cases(owner_name)
    if active_df.empty:
        return []
    overdue_df = active_df[(active_df["aging_num"] > 7) & (active_df["aging_num"] <= 21)].sort_values(by="aging_num", ascending=False)
    return overdue_df.head(top_n).to_dict(orient="records")

def get_critical_cases(owner_name: str, top_n: int = 3):
    active_df = _get_active_user_cases(owner_name)
    if active_df.empty:
        return []
    critical_df = active_df[active_df["aging_num"] > 21].sort_values(by="aging_num", ascending=False)
    return critical_df.head(top_n).to_dict(orient="records")

def get_recent_cases(owner, days=5):
    df = load_cases_df()
    user_df = _get_user_cases_by_owner(owner, df).copy()
    cutoff = pd.Timestamp.today() - pd.Timedelta(days=days)
    recent_df = user_df[user_df["reportedon"] >= cutoff]
    return recent_df.to_dict("records")

def get_latest_resolved_cases(owner_name: str, top_n: int = 3):
    df = load_cases_df()
    user_df = _get_user_cases_by_owner(owner_name, df).copy()
    resolved_df = user_df[
        (user_df["statuscode"].astype(str).str.strip() == "Resolved")
        & (user_df["closeddate"].notna())
    ].copy()
    resolved_df = resolved_df[resolved_df["closeddate"].notna()].copy()
    if resolved_df.empty:
        return []
    resolved_df = resolved_df.sort_values(by="closeddate", ascending=False)
    resolved_df["resolution_days"] = (
        (resolved_df["closeddate"] - resolved_df["reportedon"]).dt.total_seconds() / 86400.0
    ).fillna(0)
    for col in ["configurationeffort", "testingeffort", "totaleffort"]:
        if col in resolved_df.columns:
            resolved_df[col] = pd.to_numeric(resolved_df[col], errors="coerce").fillna(0)
        else:
            resolved_df[col] = 0
    return resolved_df.head(top_n).to_dict(orient="records")

# ======================================================================
# ====================== NEW ADDITIONS (NO REFACTOR) =================
# ======================================================================
# ---- Financial Year Utilities (Apr–Mar) + Business-Day Ageing ----
def _fy_label(dt: pd.Timestamp) -> str:
    """Returns FY label like 'FY25' for Apr-2024..Mar-2025."""
    if pd.isna(dt):
        return ""
    y = dt.year
    # Indian FY: Apr–Dec => next FY label; Jan–Mar => same FY label as calendar 'y'
    # Example: 2024-04-01 -> FY25; 2025-02-01 -> FY25
    return f"FY{(y + 1 if dt.month >= 4 else y) % 100:02d}"

def _fq_in_fy(dt: pd.Timestamp) -> str:
    """Q1=Apr-Jun, Q2=Jul-Sep, Q3=Oct-Dec, Q4=Jan-Mar."""
    if pd.isna(dt):
        return ""
    m = dt.month
    if 4 <= m <= 6: return "Q1"
    elif 7 <= m <= 9: return "Q2"
    elif 10 <= m <= 12:return "Q3"
    else: return "Q4"

def _fm_in_fy(dt: pd.Timestamp) -> int:
    """Financial month number within FY (Apr=1 ... Mar=12)."""
    if pd.isna(dt):
        return 0
    m = dt.month
    return (m - 3) if m >= 4 else (m + 9)

def add_business_ageing(df: pd.DataFrame) -> pd.DataFrame:
    """Adds 'ageing_bd' = business-day ageing from reportedon to closed/today."""
    if df.empty:
        return df
    today = pd.Timestamp.today()
    if "reportedon" in df.columns:
        df["reportedon"] = pd.to_datetime(df["reportedon"], errors="coerce")
    if "closeddate" in df.columns:
        df["closeddate"] = pd.to_datetime(df["closeddate"], errors="coerce")
    else:
        df["closeddate"] = pd.NaT

    def _bd(row):
        start = row.get("reportedon", pd.NaT)
        end = row.get("closeddate", pd.NaT)
        if pd.isna(start):
            return 0
        end_eff = end if pd.notna(end) else today
        val = business_days_between(start, end_eff)
        return int(val) if val is not None else 0

    df["ageing_bd"] = df.apply(_bd, axis=1)
    # convenience: mark open vs terminal
    df["is_open"] = ~df["statuscode"].astype(str).str.strip().isin(TERMINAL_STATUSES)
    return df

def get_all_owners() -> list:
    """Returns sorted unique owner names from 'currentowner' (fallback to 'ownername')."""
    df = load_cases_df()
    col = "currentowner" if "currentowner" in df.columns else "ownername"
    owners = sorted([str(x).strip() for x in df[col].dropna().unique() if str(x).strip()])
    return owners

def filter_user_fy_fq_fm(user: str, fy: str, fq: str, fm) -> pd.DataFrame:
    """
    Filters by selected user and FY/FQ/FM based on reportedon (Apr–Mar FY).
    fy: 'All' or like 'FY24'/'FY25'/'FY26'
    fq: 'All' or 'Q1'...'Q4'
    fm: 'All' or 1..12 (financial month index Apr=1..Mar=12)
    """
    df = load_cases_df()
    user_df = _get_user_cases_by_owner(user, df).copy()
    if user_df.empty:
        return user_df

    user_df["reportedon"] = pd.to_datetime(user_df["reportedon"], errors="coerce")
    user_df["FY"] = user_df["reportedon"].apply(_fy_label)
    user_df["FQ"] = user_df["reportedon"].apply(_fq_in_fy)
    user_df["FM"] = user_df["reportedon"].apply(_fm_in_fy)

    if fy and fy != "All":
        user_df = user_df[user_df["FY"] == fy]
    if fq and fq != "All":
        user_df = user_df[user_df["FQ"] == fq]
    if fm and fm != "All":
        try:
            fm_int = int(fm)
            user_df = user_df[user_df["FM"] == fm_int]
        except Exception:
            pass

    user_df = add_business_ageing(user_df)
    return user_df

def compute_user_summary_bd(filtered_df: pd.DataFrame) -> dict:
    """
    Returns summary using business-day ageing.
    Adds 'new_cases' (≤2 BD). Buckets are on OPEN cases:
    - fresh: <7 BD
    - overdue: ≥7 & <14 BD
    - critical: ≥14 BD
    """
    if filtered_df.empty:
        return {
            "owner": "",
            "total_cases": 0,
            "new_cases": 0,
            "pending_cases": 0,
            "open_cases": 0,
            "overdue_cases": 0,
            "critical_cases": 0,
            "status_breakdown": {}
        }

    df = add_business_ageing(filtered_df.copy())
    is_closed = df["closeddate"].notna()
    open_df = df[~is_closed].copy()

    total = len(df)
    new_cases = (df["ageing_bd"] <= 2).sum()  # includes new closed within 2BD as “new”
    fresh = (open_df["ageing_bd"] < 7).sum()
    overdue = ((open_df["ageing_bd"] >= 7) & (open_df["ageing_bd"] < 14)).sum()
    critical = (open_df["ageing_bd"] >= 14).sum()
    open_cases = len(open_df)
    status_counts = df["statuscode"].astype(str).value_counts().to_dict()
    owner_name = str(df.iloc[0]["currentowner"]) if "currentowner" in df.columns else ""

    return {
        "owner": owner_name,
        "total_cases": int(total),
        "new_cases": int(new_cases),
        "pending_cases": int(fresh),
        "open_cases": int(open_cases),
        "overdue_cases": int(overdue),
        "critical_cases": int(critical),
        "status_breakdown": status_counts
    }

def compute_sla_metrics_bd(filtered_df: pd.DataFrame) -> dict:
    """
    SLA metrics using business-day ageing from reportedon (weekends excluded).
    - active_in_sla: active with ageing < 7
    - sla_breached: (active + closed) with ageing > 7
    - near_breach: active with 5 <= ageing < 7
    - overdue_active: active with 7 <= ageing < 14
    - critical_active: active with ageing >= 14
    - awaiting_input: status = 'Awaiting Input' and ageing > 2
    - sla_compliance: % of closed resolved within 7BD
    - avg_resolution: average ageing of CLOSED (in business days)
    """
    if filtered_df.empty:
        return {
            "active_in_sla": 0,
            "sla_breached": 0,
            "near_breach": 0,
            "overdue_active": 0,
            "critical_active": 0,
            "awaiting_input": 0,
            "sla_compliance": 0.0,
            "avg_resolution": 0.0
        }

    df = add_business_ageing(filtered_df.copy())
    is_closed = df["closeddate"].notna()
    active = df[~is_closed].copy()
    closed = df[is_closed].copy()

    active_in_sla = int((active["ageing_bd"] < 7).sum())
    sla_breached  = int((df["ageing_bd"] > 7).sum())  # across active + closed
    near_breach   = int(((active["ageing_bd"] >= 5) & (active["ageing_bd"] < 7)).sum())
    overdue_active = int(((active["ageing_bd"] >= 7) & (active["ageing_bd"] < 14)).sum())
    critical_active = int((active["ageing_bd"] >= 14).sum())

    awaiting_mask = df["statuscode"].astype(str).str.strip().str.lower().eq("awaiting input")
    awaiting_input = int((awaiting_mask & (df["ageing_bd"] > 2)).sum())

    total_resolved = int(len(closed))
    resolved_within_sla = int((closed["ageing_bd"] <= 7).sum())
    sla_compliance = (resolved_within_sla / total_resolved * 100) if total_resolved else 0.0
    avg_resolution = float(closed["ageing_bd"].mean()) if total_resolved else 0.0

    return {
        "active_in_sla": active_in_sla,
        "sla_breached": sla_breached,
        "near_breach": near_breach,
        "overdue_active": overdue_active,
        "critical_active": critical_active,
        "awaiting_input": awaiting_input,
        "sla_compliance": round(sla_compliance, 2),
        "avg_resolution": round(avg_resolution, 2)
    }

# (No deletions below — all original functions preserved)
